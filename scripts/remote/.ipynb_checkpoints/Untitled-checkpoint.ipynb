{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib as mpl\n",
    "import itertools\n",
    "import PyVal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyparallel as ipp\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ['T', 'r', 'N', 'col sum', 'default scale', 'conn']\n",
    "col_names = ['M', 'Assets', 'RS', 'Delta', 'Solvent']\n",
    "tmp_cols = ['N_MC', 'N_nets', 'p']\n",
    "\n",
    "def combine_2_results(dict1, dict2):\n",
    "    import copy\n",
    "    res = copy.deepcopy(dict1)\n",
    "    for k in tmp_cols:\n",
    "        if k in res:\n",
    "            res.pop(k)\n",
    "    index_ok = True\n",
    "    for ind in indices:\n",
    "        if dict1[ind] != dict2[ind]:\n",
    "            index_ok = False\n",
    "    if index_ok:\n",
    "        res['Number Of Samples'] = dict1['Number Of Samples'] + dict2['Number Of Samples']\n",
    "        n1 = dict1['Number Of Samples'][1]\n",
    "        n2 = dict2['Number Of Samples'][1]\n",
    "        n_tot = n1 + n2\n",
    "        for el in col_names:\n",
    "            elv = el + ' var'\n",
    "            res[el] = (n1*dict1[el] + n2*dict2[el])/n_tot\n",
    "            res[elv] = (n1*(dict1[elv] + dict1[el]*dict1[el]) + n2*(dict2[elv] + dict2[el]*dict2[el]))/n_tot - res[el]*res[el]\n",
    "        return [res]\n",
    "    else:\n",
    "        return [dict1, dict2]\n",
    "    \n",
    "\n",
    "def results_to_df(results):\n",
    "    import copy\n",
    "    candidates = {}\n",
    "    df_list = []\n",
    "    for r_list in results:\n",
    "        for res in r_list:\n",
    "            key = tuple([res[ind] for ind in indices])\n",
    "            if key in candidates:\n",
    "                candidates[key].append(res)\n",
    "            else:\n",
    "                candidates[key] = [res]\n",
    "    for key, value in candidates.items():\n",
    "        res_in = copy.deepcopy(value)\n",
    "        while len(res_in) > 1:\n",
    "            el1 = res_in.pop()\n",
    "            el2 = res_in.pop()\n",
    "            res_in = res_in + combine_2_results(el1, el2)\n",
    "        candidates[key] = res_in[0]\n",
    "        df_list.append(res_in[0])\n",
    "    #res.set_index(indices, inplace=True)\n",
    "    return pd.DataFrame(df_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"param_grid_ER_5x_ds_vs_w\"\n",
    "inf = open(name + \".pkl\", 'rb') #'res_0_1_newnew.pkl'\n",
    "t1 = pickle.load(inf)\n",
    "inf.close()\n",
    "df1 = results_to_df(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1\n",
    "N = 80\n",
    "conn_scale = 10.\n",
    "\n",
    "for ix in df.index:\n",
    "    for ind in df.loc[ix].index:\n",
    "        if ind == 'conn':\n",
    "            df.loc[ix, ind] = df.loc[ix, ind]/conn_scale\n",
    "        elif ind == 'RS':\n",
    "            N = int(len(df.loc[ix, ind])/2.)\n",
    "            df.loc[ix, 'S'] = np.average(df.loc[ix, ind][:N])\n",
    "            df.loc[ix, 'R'] = np.average(df.loc[ix, ind][N:])\n",
    "            #df.loc[ix, 'R'] = df.loc[ix, ind]\n",
    "        elif ind == 'Delta' or ind == 'Delta var' or ind == 'Vega' or ind == 'Vega var' or ind == 'M' or ind == 'M var':\n",
    "            df.loc[ix, ind] = np.sum(df.loc[ix, ind])/N\n",
    "        else:\n",
    "            df.loc[ix, ind] = np.average(df.loc[ix, ind])\n",
    "df.drop(columns='RS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(name + \".csv\", sep=',')#, compression=\"bz2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
